package com.wtf;


import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WTFAlgorithm {
	public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
		try {
			Configuration conf1 = new Configuration();
			Job firstJob = new Job(conf1, "Who To Follow");
			job1.setJarByClass(WTFAlgorithm.class);
			job1.setMapperClass(FirstMapper.class);
			job1.setReducerClass(FirstReducer.class);
			job1.setOutputKeyClass(IntWritable.class);
			job1.setOutputValueClass(IntWritable.class);
			FileInputFormat.addInputPath(job1, new Path(args[0]));
			FileSystem fs = FileSystem.get(conf1);
			if(fs.exists(new Path(args[1]))){
				fs.delete(new Path(args[1]),true);
			}
			FileOutputFormat.setOutputPath(job1, new Path(args[1]));
			if(job1.waitForCompletion(true)){
				Job job2 = Job.getInstance(conf1, "JOB_2");
				job2.setMapperClass(SecondMapper.class);
				job2.setReducerClass(SecondReducer.class);
				job2.setOutputKeyClass(IntWritable.class);
				job2.setOutputValueClass(IntWritable.class);
				FileInputFormat.addInputPath(job2, new Path(args[1]));
				if(fs.exists(new Path(args[2]))){
					fs.delete(new Path(args[2]),true);
				}
				FileOutputFormat.setOutputPath(job2, new Path(args[2]));
				job2.waitForCompletion(true);			
			}
		} 
		catch (Exception e) {
			e.printStackTrace();
		}
	}


}